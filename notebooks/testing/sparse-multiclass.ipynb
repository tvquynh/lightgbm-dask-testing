{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook tests `lightgbm.dask`'s behavior with sparse inputs to `pred_contrib()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from dask import delayed\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from lightgbm.dask import DaskLGBMClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from scipy.sparse import csc_matrix\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the dashboard: http://127.0.0.1:8787/status\n"
     ]
    }
   ],
   "source": [
    "n_workers = 3\n",
    "cluster = LocalCluster(n_workers=n_workers)\n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(n_workers)\n",
    "\n",
    "print(f\"View the dashboard: {cluster.dashboard_link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 50\n",
    "X, y = make_blobs(n_samples=100, centers=3, random_state=42)\n",
    "rnd = np.random.RandomState(42)\n",
    "dX = da.from_array(X, chunks=(chunk_size, X.shape[1])).map_blocks(csc_matrix)\n",
    "dy = da.from_array(y, chunks=chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding random open ports for workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/dask.py:324: UserWarning: Parameter n_jobs will be ignored.\n",
      "  _log_warning(f\"Parameter {param_alias} will be ignored.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- str(data) ---\n",
      "dask.array<csc_matrix, shape=(100, 2), dtype=float64, chunksize=(50, 2), chunktype=scipy.csc_matrix>\n",
      "-----------------\n",
      "--- str(first part) ---\n",
      "  (0, 0)\t-7.726420909219675\n",
      "  (1, 0)\t5.453396053597771\n",
      "  (2, 0)\t-2.978672008987702\n",
      "  (3, 0)\t6.042673147164201\n",
      "  (4, 0)\t-6.521839830802987\n",
      "  (5, 0)\t3.649342511097413\n",
      "  (6, 0)\t-2.1779341916491863\n",
      "  (7, 0)\t4.4202069483905895\n",
      "  (8, 0)\t4.736956385576142\n",
      "  (9, 0)\t-3.6601912004750528\n",
      "  (10, 0)\t-3.053580347577933\n",
      "  (11, 0)\t-6.65216725654714\n",
      "  (12, 0)\t-6.357685625534373\n",
      "  (13, 0)\t-3.6155325970587784\n",
      "  (14, 0)\t-1.7707310430573397\n",
      "  (15, 0)\t-7.950519689212382\n",
      "  (16, 0)\t-6.602936391821251\n",
      "  (17, 0)\t-2.581207744633084\n",
      "  (18, 0)\t-7.763484627352403\n",
      "  (19, 0)\t-6.406389566577725\n",
      "  (20, 0)\t-2.9726153158652124\n",
      "  (21, 0)\t-6.956728900565374\n",
      "  (22, 0)\t-7.326142143218291\n",
      "  (23, 0)\t-2.147802017544336\n",
      "  (24, 0)\t-2.5450236621627016\n",
      "  :\t:\n",
      "  (25, 1)\t10.071408354417237\n",
      "  (26, 1)\t1.552524361175373\n",
      "  (27, 1)\t-7.737267149692229\n",
      "  (28, 1)\t-6.093024989533495\n",
      "  (29, 1)\t-8.200566206360223\n",
      "  (30, 1)\t-6.647855896114943\n",
      "  (31, 1)\t2.234224956120621\n",
      "  (32, 1)\t2.2747170262743444\n",
      "  (33, 1)\t-7.7007919116276575\n",
      "  (34, 1)\t9.78172085735123\n",
      "  (35, 1)\t8.722592378405045\n",
      "  (36, 1)\t7.589537941984865\n",
      "  (37, 1)\t8.629203847782005\n",
      "  (38, 1)\t2.3019207936004165\n",
      "  (39, 1)\t-0.0143992306601608\n",
      "  (40, 1)\t-7.8179346331910695\n",
      "  (41, 1)\t8.828627151534505\n",
      "  (42, 1)\t0.8044916463212\n",
      "  (43, 1)\t9.211147364067445\n",
      "  (44, 1)\t8.713182432609033\n",
      "  (45, 1)\t2.4467621145759137\n",
      "  (46, 1)\t-6.695475734743642\n",
      "  (47, 1)\t-6.49479221354711\n",
      "  (48, 1)\t-5.42657551611863\n",
      "  (49, 1)\t1.4714126403561956\n",
      "(50, 2)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask_clf = DaskLGBMClassifier(n_estimators=5, num_leaves=2, tree_learner=\"data\")\n",
    "dask_clf.fit(dX, dy)\n",
    "\n",
    "preds = dask_clf.predict(dX, pred_contrib=True)\n",
    "preds_computed = preds.compute()\n",
    "\n",
    "# print(\n",
    "#     type(preds),\n",
    "#     type(preds.partitions[0].compute()),\n",
    "#     type(preds_computed),\n",
    "#     f\"{dask_clf.n_classes_} classes, {dX.shape[1]} features\",\n",
    "# )\n",
    "# print(\"---\")\n",
    "# print(dX.partitions[0].compute())\n",
    "# print(\"---\")\n",
    "preds.compute().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 <class 'list'>\n",
      "---\n",
      "[<100x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 300 stored elements in Compressed Sparse Column format>, <100x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 300 stored elements in Compressed Sparse Column format>, <100x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 300 stored elements in Compressed Sparse Column format>]\n"
     ]
    }
   ],
   "source": [
    "X = dX.compute()\n",
    "y = dy.compute()\n",
    "\n",
    "local_clf = LGBMClassifier()\n",
    "local_clf.fit(X=dX.compute(), y=y)\n",
    "local_preds = local_clf.predict(dX.compute().tocsc(), pred_contrib=True)\n",
    "\n",
    "print(local_clf.n_classes_, type(local_preds))\n",
    "print(\"---\")\n",
    "print(local_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "# type(dX._meta) is scipy.sparse.csc.csc_matrix\n",
    "# isinstance(dX._meta, (scipy.sparse.csc.csc_matrix, scipy.sparse.csr.csr_matrix))\n",
    "# m = dX.to_delayed().ravel()\n",
    "# dir(m[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = [\n",
    "#     delayed(lgb.dask._predict_part)(\n",
    "#         chunk,\n",
    "#         model=local_clf,\n",
    "#         raw_score=False,\n",
    "#         pred_proba=False,\n",
    "#         pred_leaf=False,\n",
    "#         pred_contrib=False,\n",
    "#     )\n",
    "#     for chunk in dX.to_delayed().ravel()\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = db.from_delayed(\n",
    "    list(dX.to_delayed().ravel())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import wait\n",
    "\n",
    "type(dX.partitions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "\n",
    "# def _predict_accumulate(preds_so_far, new_chunk, pred_fn):\n",
    "#     #raise RuntimeError(preds_so_far)\n",
    "# #     try:\n",
    "# #         preds = pred_fn(new_chunk.compute())\n",
    "# #     except:\n",
    "# #         raise RuntimeError(new_chunk)\n",
    "#     preds = pred_fn(new_chunk.compute())\n",
    "#     if preds_so_far is None:\n",
    "#         return preds\n",
    "#     else:\n",
    "#         for i in range(len(preds)):\n",
    "#             preds_so_far[i] = lgb.dask._concat([preds_so_far[i], preds[i]])\n",
    "#     return preds_so_far\n",
    "\n",
    "# bag = db.from_sequence(dX.partitions)\n",
    "\n",
    "# predict_fn = partial(\n",
    "#     lgb.dask._predict_part,\n",
    "#     model=local_clf,\n",
    "#     raw_score=False,\n",
    "#     pred_proba=False,\n",
    "#     pred_leaf=False,\n",
    "#     pred_contrib=True,\n",
    "# )\n",
    "\n",
    "# pred_accum = partial(\n",
    "#     _predict_accumulate,\n",
    "#     pred_fn=predict_fn\n",
    "# )\n",
    "\n",
    "# v = bag.fold(\n",
    "#     binop=pred_accum,\n",
    "#     combine=pred_accum,\n",
    "#     initial=None\n",
    "# )\n",
    "\n",
    "# v.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS WORKED!!!\n",
    "\n",
    "import dask.bag as db\n",
    "from functools import partial\n",
    "\n",
    "bag = db.from_sequence(dX.partitions)\n",
    "\n",
    "def _combine_preds(preds_so_far, new_chunk):\n",
    "    #raise RuntimeError(preds_so_far)\n",
    "    for i in range(len(preds_so_far)):\n",
    "        preds_so_far[i] = lgb.dask._concat([preds_so_far[i], new_chunk[i]])\n",
    "    return preds_so_far\n",
    "\n",
    "predict_fn = partial(\n",
    "    lgb.dask._predict_part,\n",
    "    model=local_clf,\n",
    "    raw_score=False,\n",
    "    pred_proba=False,\n",
    "    pred_leaf=False,\n",
    "    pred_contrib=True,\n",
    ")\n",
    "\n",
    "def _predict_part_binop(_ignore, chunk, pred_fn):\n",
    "    return predict_fn(chunk.compute())\n",
    "\n",
    "predict_part_binop = partial(\n",
    "    _predict_part_binop,\n",
    "    pred_fn=predict_fn\n",
    ")\n",
    "\n",
    "v = bag.fold(\n",
    "    binop=predict_part_binop,\n",
    "    combine=_combine_preds,\n",
    "    initial=None\n",
    ")\n",
    "\n",
    "#v.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<100x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 300 stored elements in Compressed Sparse Row format>,\n",
       " <100x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 300 stored elements in Compressed Sparse Row format>,\n",
       " <100x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 300 stored elements in Compressed Sparse Row format>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _concat_lists(x, y):\n",
    "    print(\"aaa\")\n",
    "    print(\"--- this ---\")\n",
    "    print(x)\n",
    "    #print(y)\n",
    "    print(\"--- that ---\")\n",
    "    if x is None:\n",
    "        return y\n",
    "    else:\n",
    "        return([\n",
    "            lgb.dask._concat([x[i], y[i]])\n",
    "            for i in range(len(x))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = bag.map(\n",
    "    func=lgb.dask._predict_part,\n",
    "    model=local_clf,\n",
    "    raw_score=False,\n",
    "    pred_proba=False,\n",
    "    pred_leaf=False,\n",
    "    pred_contrib=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "predict_fn = partial(\n",
    "    lgb.dask._predict_part,\n",
    "    model=local_clf,\n",
    "    raw_score=False,\n",
    "    pred_proba=False,\n",
    "    pred_leaf=False,\n",
    "    pred_contrib=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = v.accumulate(\n",
    "    binop=_concat_lists,\n",
    "    initial=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = bag.map_partitions(\n",
    "    func=lgb.dask._predict_part,\n",
    "    model=local_clf,\n",
    "    raw_score=False,\n",
    "    pred_proba=False,\n",
    "    pred_leaf=False,\n",
    "    pred_contrib=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction(perpartition, aggregate, split_every=None, out_type=<class 'dask.bag.core.Item'>, name=None) method of dask.bag.core.Bag instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(v.accumulate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://github.com/microsoft/LightGBM/pull/3866\n",
    "\n",
    "https://docs.dask.org/en/latest/bag-creation.html\n",
    "\n",
    "https://github.com/dask/dask/issues/7589\n",
    "\n",
    "https://github.com/microsoft/LightGBM/issues/3881\n",
    "\n",
    "https://github.com/microsoft/LightGBM/pull/4351/files#diff-4583a656084ea62b391a061e1c1f533e3e99e1d1a6021a5408032d80c6bdd394"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
